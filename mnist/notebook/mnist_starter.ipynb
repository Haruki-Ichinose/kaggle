{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07d36a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 02:12:31.867000: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-22 02:12:31.868638: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-22 02:12:31.874683: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-22 02:12:31.887888: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745255551.910718   10144 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745255551.924864   10144 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745255551.947621   10144 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745255551.947647   10144 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745255551.947649   10144 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745255551.947650   10144 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-22 02:12:31.953896: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 784 columns]\n",
      "Training data shape: (42000, 28, 28, 1)\n",
      "Test data shape: (28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# データの読み込み\n",
    "train = pd.read_csv('/home/haruki/kaggle/mnist/data/train.csv')\n",
    "test = pd.read_csv('/home/haruki/kaggle/mnist/data/test.csv')\n",
    "\n",
    "# 最初の5行を表示\n",
    "print(train.head())\n",
    "print(test.head())\n",
    "\n",
    "# train.csvから特徴量とラベルを分ける\n",
    "X_train = train.drop('label', axis=1).values  # ピクセルデータ\n",
    "y_train = train['label'].values  # ラベルデータ\n",
    "\n",
    "# test.csvから特徴量を取り出す\n",
    "X_test = test.values  # ピクセルデータ\n",
    "\n",
    "# データの前処理\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255  # 画像サイズ28x28x1に変換し、正規化\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "# ラベルをone-hotエンコーディング\n",
    "y_train = to_categorical(y_train, 10)\n",
    "\n",
    "# データの確認\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "175e0cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8100 - loss: 0.5840 - val_accuracy: 0.9590 - val_loss: 0.1308\n",
      "Epoch 2/5\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9755 - loss: 0.0764 - val_accuracy: 0.9836 - val_loss: 0.0506\n",
      "Epoch 3/5\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9851 - loss: 0.0456 - val_accuracy: 0.9837 - val_loss: 0.0532\n",
      "Epoch 4/5\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9885 - loss: 0.0362 - val_accuracy: 0.9892 - val_loss: 0.0388\n",
      "Epoch 5/5\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9917 - loss: 0.0276 - val_accuracy: 0.9879 - val_loss: 0.0414\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step\n",
      "Predictions (first 10):\n",
      "[2 0 9 9 3 7 0 3 0 3]\n"
     ]
    }
   ],
   "source": [
    "# CNNモデルの構築（前回のコードと同じ）\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# モデルの訓練\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# 予測を行う（y_testはないので、y_trainに基づいて評価はできません）\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 予測結果を出力（最初の10件の予測結果を表示）\n",
    "print(\"Predictions (first 10):\")\n",
    "print(np.argmax(predictions[:10], axis=1))  # 各画像に対する予測ラベルを表示\n",
    "\n",
    "# 必要なら、予測結果を送信用に保存する\n",
    "# output = pd.DataFrame({'ImageId': np.arange(1, len(X_test) + 1), 'Label': np.argmax(predictions, axis=1)})\n",
    "# output.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38f36e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step\n",
      "提出用ファイルが作成されました！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 予測を行う（X_testに対して）\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 予測結果をラベルに変換\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# ImageIdとLabelを含むデータフレームを作成\n",
    "output = pd.DataFrame({'ImageId': np.arange(1, len(X_test) + 1), 'Label': predicted_labels})\n",
    "\n",
    "# 提出用ファイルとして保存\n",
    "output.to_csv('/home/haruki/kaggle/mnist/submission.csv', index=False)\n",
    "\n",
    "print(\"提出用ファイルが作成されました！\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
